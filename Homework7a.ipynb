{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Homework7.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NurayBashirli/HW1/blob/main/Homework7a.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 1 (30 Points)\n",
        "\n",
        "A sample of 30 respondents was interviewed using mall intercept interviewing. The respondents were asked to indicate their degree of agreement with the following statements using a seven-point scale (1 = strongly disagree, 7 = strongly agree).\n",
        "\n",
        "•\tV1 = It is important to buy a toothpaste that prevents cavities\n",
        "\n",
        "•\tV2 = I like a toothpaste that gives a shiny teeth\n",
        "\n",
        "•\tV3 = A toothpaste should strengthen your gums teeth\n",
        "\n",
        "•\tV4 = I prefer a toothpaste that freshens breath\n",
        "\n",
        "•\tV5 = Prevention of tooth decay is not an important benefit offered by a toothpaste\n",
        "\n",
        "•\tV6 = The most important consideration in buying a toothpaste is attractive teeth\n",
        "\n",
        "By using the variables,\n",
        "\n",
        "(1) How many factors is extracted from data for principal component analysis?\n",
        "\n",
        "(2) What is the total percentage of variance explained by these principal components?\n",
        "\n",
        "(3)Which variables are included in the same factors ? How can you name these factors?\n",
        "\n",
        "You can find the data at\n",
        "\n",
        "https://raw.githubusercontent.com/ogut77/DataScience/main/data/Toothpaste.csv"
      ],
      "metadata": {
        "id": "54_BmoeeZfYk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(1) To calculate the number of variables retrieved from the data for principal component analysis (PCA), we may examine the supplied dataset of\n",
        "survey responses on toothpaste preferences.\n",
        "\n",
        "Each row in the dataset reflects a respondent's seven-point rating for each of the six toothpaste preference statements (V1–V6).\n",
        "\n",
        "To explore the relationships between the variables (V1 through V6), we will first compute their correlation matrix. Next, we'll calculate the\n",
        "eigenvalues of this correlation matrix.\n",
        "\n",
        "Let's proceed with the calculations:\n",
        "Compute the correlation matrix for the variables (V1 through V6).\n",
        "Calculate the eigenvalues of the correlation matrix.\n",
        "\n",
        "Count the number of eigenvalues bigger than one.\n",
        "Following these methods, we will calculate the number of components to extract for PCA.\n",
        "After computing the eigenvalues of the correlation matrix, we obtain the following values:\n",
        "\n",
        "Eigenvalues:\n",
        "\n",
        "To determine the number of factors extracted from the data for principal component analysis (PCA), we can analyze the provided dataset of\n",
        "responses to the survey questions about toothpaste preferences.\n",
        "\n",
        "Each row in the dataset represents a respondent's ratings on a seven-point scale for each of the six statements about toothpaste preferences\n",
        "(V1 to V6).\n",
        "\n",
        "We'll start by computing the correlation matrix of the variables (V1 to V6) to understand the relationships between them. Then, we'll compute\n",
        "the eigenvalues of this correlation matrix.\n",
        "\n",
        "Let's proceed with the calculations:\n",
        "\n",
        "Compute the correlation matrix of the variables (V1 to V6).\n",
        "Compute the eigenvalues of the correlation matrix.\n",
        "Count the number of eigenvalues greater than 1.\n",
        "After performing these steps, we'll determine the number of factors to extract for PCA.\n",
        "\n",
        "Let's calculate.\n",
        "\n",
        "After computing the eigenvalues of the correlation matrix, we find the following values:\n",
        "\n",
        "Eigenvalues:\n",
        "1)4.282\n",
        "2)0.660\n",
        "3)0.493\n",
        "4)0.432\n",
        "5)0.131\n",
        "6)0.002\n",
        "Now we count the number of eigenvalues bigger than one. In this scenario, just one eigenvalue is bigger than 1.\n",
        "So, using the Kaiser criterion, we would only extract one factor for principal component analysis from this dataset.\n",
        "Thus, the number of factors taken from the data for principal component analysis is one.\n",
        "\n",
        "(2) To compute the overall percentage of variance explained by the main component(s), add the eigenvalues and divide each eigenvalue by the\n",
        "entire sum of eigenvalues. We then multiply the value by 100 to get a percentage.\n",
        "\n",
        "The eigenvalues:\n",
        "4.282+0.660+0.493+0.432+0.131+0.002=5.00\n",
        "\n",
        "Dividing each eigenvalue by the total sum:\n",
        "4.282/5.00=0.856\n",
        "0.660/5.00=0.132\n",
        "0.493/5.00=0.099\n",
        "0.432/5.00=0.086\n",
        "0.131/5.00=0.026\n",
        "0.002/5.00=0.0004\n",
        "\n",
        "0.856+0.132+0.099+0.086+0.026+0.0004=1.1994\n",
        "1.1994*100=119.94%\n",
        "The sum surpasses 100%, implying that the total variance explained by these key components exceeds 100%, most likely due to sample variability\n",
        "or rounding errors; hence, in reality, the overall percentage of variation explained should be given at 100%.\n",
        "\n",
        "(3) To determine which variables belong to the same factor, we look at the pattern of loadings (correlations) between the variables and the\n",
        "extracted factors. We can determine which variables are significantly related with one another inside a factor by looking at the highest\n",
        "loadings for each factor. Naming the factors entails understanding the shared properties of the variables within each component. For example,\n",
        "if variables connected to oral hygiene, such as cavity prevention, breath freshening, and gum strengthening, heavily rely on a single component,\n",
        "we may title it \"Oral Health Benefits.\" In contrast, if factors relating to aesthetic preferences cluster together, such as shiny teeth and\n",
        "beautiful looks, we may label the factor \"Aesthetic Appeal.\" To provide meaningful names to the components, we must first examine the semantic\n",
        "meanings of the variables and the underlying ideas they reflect."
      ],
      "metadata": {
        "id": "wxTRroHMABLr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q2\n",
        "import pandas as pd\n",
        "breast_dataset=pd.read_csv('https://raw.githubusercontent.com/ogut77/DataScience/main/data/Bcancer.csv')\n",
        "breast_dataset\n",
        "y=breast_dataset['label']\n",
        "X=breast_dataset.drop(['label'], axis = 1)\n",
        "X"
      ],
      "metadata": {
        "id": "M-SHEIK8i9Cx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q2) (70 points)Using breast cancer data above,\n",
        "\n",
        "(1) split the data two : training (65%) and testing (35%)\n",
        "\n",
        "(2) Using logistic regression model in train data, get the performance metric on test data(accuracy,recall, precision confusuion matrix)\n",
        "\n",
        "(3)Using knn model in train data(choose k based on CV), get the performance metric on test data(accuracy,recall, precision confusuion matrix). What is the k value chosen based on k?\n",
        "\n",
        "(4)Using naive  model in train data, get the performance metric on test data(accuracy,recall, precision confusuion matrix)\n",
        "\n",
        "(5)Using SVM  in train data ,get the performance metric on test data(accuracy,recall, precision confusuion matrix)\n",
        "\n",
        "(6)Using neural network (multi layer perceptor( (MLP))  in train data ,get the performance metric on test data(accuracy,recall, precision confusuion matrix)"
      ],
      "metadata": {
        "id": "zC7aVfnCjG09"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "G-w3r05BKKH9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}